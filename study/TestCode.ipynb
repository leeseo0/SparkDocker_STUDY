{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7b2c87-14c5-47d0-a067-cad9973e39d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "<class 'int'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 15\n",
    "c = \"안녕\"\n",
    "print(a+b)\n",
    "print(type(a+b))\n",
    "print(type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b8e4f26-01ad-4968-a9d8-2372381ff730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f840bf-2187-4c0e-8cc7-b7974fc3963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Spark\") \\\n",
    "    .config(\"soark.sql.rep1.eagerEval.enabled\", True) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b406829-8df8-4a80-acf3-c463289f2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[46] at readRDDFromFile at PythonRDD.scala:287\n",
      "Z,1\n",
      "A,20\n",
      "B,30\n",
      "C,40\n",
      "B,30\n",
      "B,60\n"
     ]
    }
   ],
   "source": [
    "data=[(\"Z\", 1),(\"A\", 20),(\"B\", 30),(\"C\", 40),(\"B\", 30),(\"B\", 60)]\n",
    "inputRDD = spark.sparkContext.parallelize(data)  # 타입RDD로 변경\n",
    "print(inputRDD)\n",
    "inputRDD.collect() # collect : spark에서 print문과 같음\n",
    "py_rdd = inputRDD.collect()\n",
    "for i in py_rdd:\n",
    "   print(i[0] + \",\" + str(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6da55c5d-4bfc-4877-8b19-f7c9d9671df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count : 7\n",
      "countByValue :  defaultdict(<class 'int'>, {1: 1, 2: 2, 3: 2, 4: 1, 5: 1})\n"
     ]
    }
   ],
   "source": [
    "listRdd = spark.sparkContext.parallelize([1,2,3,4,5,3,2])\n",
    "listRdd.collect()\n",
    "\n",
    "print(\"Count : \"+str(listRdd.count()))\n",
    "\n",
    "print(\"countByValue :  \"+str(listRdd.countByValue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "911ee0cf-2bb3-4de9-aa33-e2aa814eee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first :  1\n",
      "first :  ('Z', 1)\n"
     ]
    }
   ],
   "source": [
    "inputRDD.collect()\n",
    "listRdd.collect()\n",
    "\n",
    "print(\"first :  \"+str(listRdd.first()))\n",
    "print(\"first :  \"+str(inputRDD.first()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522bdd20-0ae9-41da-9608-1a8d48690005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top : [5, 4]\n",
      "top : [('Z', 1), ('C', 40)]\n",
      "min :  1\n",
      "min :  ('A', 20)\n",
      "max :  5\n",
      "max :  ('Z', 1)\n"
     ]
    }
   ],
   "source": [
    "inputRDD.collect()\n",
    "listRdd.collect()\n",
    "\n",
    "print(\"top : \"+str(listRdd.top(2)))\n",
    "\n",
    "print(\"top : \"+str(inputRDD.top(2)))\n",
    "\n",
    "print(\"min :  \"+str(listRdd.min()))\n",
    "\n",
    "print(\"min :  \"+str(inputRDD.min()))\n",
    "\n",
    "print(\"max :  \"+str(listRdd.max()))\n",
    "\n",
    "print(\"max :  \"+str(inputRDD.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb5f852-26fb-4995-9301-efeeb6dd1a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c'], ['d', 'e', 'f'], ['g', 'h', 'i']]\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']\n"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "rdd = sc.parallelize(['a,b,c','d,e,f','g,h,i'])\n",
    "\n",
    "map_rdd = rdd.map(lambda x: x.split(','))\n",
    "print(map_rdd.collect())\n",
    "\n",
    "flatmap_rdd = rdd.flatMap(lambda x: x.split(','))\n",
    "print(flatmap_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bec1a70-155c-4964-b56c-3693fc703425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Z', 1)\n",
      "('A', 20)\n",
      "('B', 120)\n",
      "('C', 40)\n"
     ]
    }
   ],
   "source": [
    "data=[(\"Z\", 1),(\"A\", 20),(\"B\", 30),(\"C\", 40),(\"B\", 30),(\"B\", 60)]\n",
    "inputRDD = spark.sparkContext.parallelize(data)\n",
    "\n",
    "rdd2=inputRDD.reduceByKey(lambda a,b: a+b)\n",
    "\n",
    "rdd2.collect()\n",
    "\n",
    "for element in rdd2.collect():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f17bafa-054b-4525-a070-43eef768dc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_count: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 23.08.31\n",
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "dfFromRDD = rdd.toDF()\n",
    "dfFromRDD.printSchema()\n",
    "\n",
    "dfFromRDD1 = rdd.toDF(columns)\n",
    "dfFromRDD1.printSchema()\n",
    "\n",
    "dfFromRDD2 = spark.createDataFrame(rdd).toDF(*columns)\n",
    "dfFromRDD2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2abcb11-4665-459f-90fb-f024670da9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "]\n",
    "\n",
    "schema = StructType([ \n",
    "    StructField(\"firstname\",StringType(),True), \n",
    "    StructField(\"middlename\",StringType(),True), \n",
    "    StructField(\"lastname\",StringType(),True), \n",
    "    StructField(\"id\", StringType(), True), \n",
    "    StructField(\"gender\", StringType(), True), \n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "  ])\n",
    " \n",
    "df = spark.createDataFrame(data=data2,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d42509f4-f8e8-458b-a5d4-f6dc71843755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------------------+\n",
      "|_c0|_c1                                                                               |\n",
      "+---+----------------------------------------------------------------------------------+\n",
      "|Id |JsonValue                                                                         |\n",
      "|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}        |\n",
      "|2  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PASEO COSTA DEL SUR\",\"State\":\"PR\"}|\n",
      "|3  |{\"Zipcode\":709,\"ZipCodeType\":\"STANDARD\",\"City\":\"BDA SAN LUIS\",\"State\":\"PR\"}       |\n",
      "|4  |{\"Zipcode\":76166,\"ZipCodeType\":\"UNIQUE\",\"City\":\"CINGULAR WIRELESS\",\"State\":\"TX\"}  |\n",
      "|5  |{\"Zipcode\":76177,\"ZipCodeType\":\"STANDARD\",\"City\":\"FORT WORTH\",\"State\":\"TX\"}       |\n",
      "|6  |{\"Zipcode\":76177,\"ZipCodeType\":\"STANDARD\",\"City\":\"FT WORTH\",\"State\":\"TX\"}         |\n",
      "|7  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"URB EUGENE RICE\",\"State\":\"PR\"}    |\n",
      "|8  |{\"Zipcode\":85209,\"ZipCodeType\":\"STANDARD\",\"City\":\"MESA\",\"State\":\"AZ\"}             |\n",
      "|9  |{\"Zipcode\":85210,\"ZipCodeType\":\"STANDARD\",\"City\":\"MESA\",\"State\":\"AZ\"}             |\n",
      "|10 |{\"Zipcode\":32046,\"ZipCodeType\":\"STANDARD\",\"City\":\"HILLIARD\",\"State\":\"FL\"}         |\n",
      "+---+----------------------------------------------------------------------------------+\n",
      "\n",
      "+----------------------------------------------------------------------------------+\n",
      "|value                                                                             |\n",
      "+----------------------------------------------------------------------------------+\n",
      "|{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}        |\n",
      "|{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PASEO COSTA DEL SUR\",\"State\":\"PR\"}|\n",
      "|{\"Zipcode\":709,\"ZipCodeType\":\"STANDARD\",\"City\":\"BDA SAN LUIS\",\"State\":\"PR\"}       |\n",
      "|{\"Zipcode\":76166,\"ZipCodeType\":\"UNIQUE\",\"City\":\"CINGULAR WIRELESS\",\"State\":\"TX\"}  |\n",
      "|{\"Zipcode\":76177,\"ZipCodeType\":\"STANDARD\",\"City\":\"FORT WORTH\",\"State\":\"TX\"}       |\n",
      "|{\"Zipcode\":76177,\"ZipCodeType\":\"STANDARD\",\"City\":\"FT WORTH\",\"State\":\"TX\"}         |\n",
      "|{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"URB EUGENE RICE\",\"State\":\"PR\"}    |\n",
      "|{\"Zipcode\":85209,\"ZipCodeType\":\"STANDARD\",\"City\":\"MESA\",\"State\":\"AZ\"}             |\n",
      "|{\"Zipcode\":85210,\"ZipCodeType\":\"STANDARD\",\"City\":\"MESA\",\"State\":\"AZ\"}             |\n",
      "|{\"Zipcode\":32046,\"ZipCodeType\":\"STANDARD\",\"City\":\"HILLIARD\",\"State\":\"FL\"}         |\n",
      "+----------------------------------------------------------------------------------+\n",
      "\n",
      "+-------------------+-----+-----------+-------+\n",
      "|City               |State|ZipCodeType|Zipcode|\n",
      "+-------------------+-----+-----------+-------+\n",
      "|PARC PARQUE        |PR   |STANDARD   |704    |\n",
      "|PASEO COSTA DEL SUR|PR   |STANDARD   |704    |\n",
      "|BDA SAN LUIS       |PR   |STANDARD   |709    |\n",
      "|CINGULAR WIRELESS  |TX   |UNIQUE     |76166  |\n",
      "|FORT WORTH         |TX   |STANDARD   |76177  |\n",
      "|FT WORTH           |TX   |STANDARD   |76177  |\n",
      "|URB EUGENE RICE    |PR   |STANDARD   |704    |\n",
      "|MESA               |AZ   |STANDARD   |85209  |\n",
      "|MESA               |AZ   |STANDARD   |85210  |\n",
      "|HILLIARD           |FL   |STANDARD   |32046  |\n",
      "+-------------------+-----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.csv(\"./simple_zipcodes.csv\")\n",
    "df2.show(truncate=False)\n",
    "df2 = spark.read.text(\"./simple_zipcodes.txt\")\n",
    "df2.show(truncate=False)\n",
    "df2 = spark.read.json(\"./simple_zipcodes.json\")\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceebfa48-065e-48a0-9e2f-90199481742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmptyRDD[114] at emptyRDD at NativeMethodAccessorImpl.java:0\n",
      "ParallelCollectionRDD[115] at readRDDFromFile at PythonRDD.scala:287\n"
     ]
    }
   ],
   "source": [
    "emptyRDD = spark.sparkContext.emptyRDD()\n",
    "print(emptyRDD)\n",
    "rdd2= spark.sparkContext.parallelize([])\n",
    "print(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93866622-2e6b-447c-ae5d-25f964c2cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.50 DataFrame 생성 / StructType\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "schema = StructType([\n",
    "  StructField('firstname', StringType(), True),\n",
    "  StructField('middlename', StringType(), True),\n",
    "  StructField('lastname', StringType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(emptyRDD,schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e5a489-2229-4ac9-bbe9-f3e959ed4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.51 emptyRDD\n",
    "# to.DF함수, 함수 내 스키마 구조 지정\n",
    "df1 = emptyRDD.toDF(schema)\n",
    "df1.printSchema()\n",
    "\n",
    "# 첫번째 인자: [], 두번째 인자: 생성했던 스키마 구조\n",
    "df2 = spark.createDataFrame([], schema)\n",
    "df2.printSchema()\n",
    "\n",
    "# 첫번째 인자: [], 두번째 인자: 비어있는 구조\n",
    "df3 = spark.createDataFrame([], StructType([]))\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebab9ce6-485d-4345-ab08-327f7adaf859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.52 RDD to Dataframe\n",
    "# parallelize()를 통해 RDD 형태 데이터 생성\n",
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "rdd = spark.sparkContext.parallelize(dept)\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "df2 = rdd.toDF(deptColumns) # 변수.toDF(\"컬럼명 변수\"):Dataframe생성\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d4a4b46-7602-466d-a75a-5370e5a53120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.53 첫번째 인자: RDD변수, 두번째 인자:컬럼명 변수 -> Dataframe생성\n",
    "deptDF = spark.createDataFrame(rdd, deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c2780cd-dbd0-4e1e-be54-1d3890636bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.54 두번째 인자: StructType로 구성한 구조\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "deptSchema = StructType([       \n",
    "    StructField('dept_name', StringType(), True),\n",
    "    StructField('dept_id', StringType(), True)\n",
    "])\n",
    "deptDF1 = spark.createDataFrame(rdd, schema = deptSchema)\n",
    "deptDF1.printSchema()\n",
    "deptDF1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "890df23d-c5b1-421b-abf2-68f7956aa39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n",
      "   dept_name  dept_id\n",
      "0    Finance       10\n",
      "1  Marketing       20\n",
      "2      Sales       30\n",
      "3         IT       40\n"
     ]
    }
   ],
   "source": [
    "# p.58 \n",
    "# Dataframe 생성\n",
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "rdd = spark.sparkContext.parallelize(dept)\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "df2 = rdd.toDF(deptColumns)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "# Python Dataframe으로 변경\n",
    "import pandas\n",
    "pandasDF = df2.toPandas()\n",
    "print(pandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbcc41eb-46e8-4322-899b-819d7e66cda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.59 PySpark의 Dataframe으로 변경\n",
    "PySparkDF = spark.createDataFrame(pandasDF)\n",
    "PySparkDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14f27677-3251-444e-b78c-11c69e30a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Seqno|               Quote|\n",
      "+-----+--------------------+\n",
      "|    1|Be the change tha...|\n",
      "|    2|Everyone thinks o...|\n",
      "|    3|The purpose of ou...|\n",
      "|    4|            Be cool.|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.60 show함수\n",
    "from pyspark.sql import SparkSession\n",
    "columns = [\"Seqno\",\"Quote\"]\n",
    "data = [(\"1\", \"Be the change that you wish to see in the world\"),\n",
    "    (\"2\", \"Everyone thinks of changing the world, but no one thinks of changing himself.\"),\n",
    "    (\"3\", \"The purpose of our lives is to be happy.\"),\n",
    "    (\"4\", \"Be cool.\")]\n",
    "df = spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "982f55fc-0b5e-4e8b-ac3a-05faf501f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------+\n",
      "|Seqno|Quote                                                                        |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|1    |Be the change that you wish to see in the world                              |\n",
      "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
      "|3    |The purpose of our lives is to be happy.                                     |\n",
      "|4    |Be cool.                                                                     |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|Seqno|Quote                                                                        |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|1    |Be the change that you wish to see in the world                              |\n",
      "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----+-------------------------+\n",
      "|Seqno|                    Quote|\n",
      "+-----+-------------------------+\n",
      "|    1|Be the change that you...|\n",
      "|    2|Everyone thinks of cha...|\n",
      "+-----+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "-RECORD 0--------------------------\n",
      " Seqno | 1                         \n",
      " Quote | Be the change that you... \n",
      "-RECORD 1--------------------------\n",
      " Seqno | 2                         \n",
      " Quote | Everyone thinks of cha... \n",
      "-RECORD 2--------------------------\n",
      " Seqno | 3                         \n",
      " Quote | The purpose of our liv... \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.61\n",
    "df.show(truncate=False) # 전체\n",
    "df.show(2,truncate=False) # 원하는 행, 전체\n",
    "df.show(2,truncate=25) # 원하는 행, 정수값만큼\n",
    "df.show(n=3,truncate=25,vertical=True) # 수직 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42353d97-7ca2-46b1-85ca-b526fd803663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name.fname: string (nullable = true)\n",
      " |-- gender: long (nullable = true)\n",
      "\n",
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|    23|\n",
      "|    40|\n",
      "+------+\n",
      "\n",
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|    23|\n",
      "|    40|\n",
      "+------+\n",
      "\n",
      "+----------+\n",
      "|name.fname|\n",
      "+----------+\n",
      "|     James|\n",
      "|       Ann|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.62 Column\n",
    "data=[(\"James\",23),(\"Ann\",40)]\n",
    "df=spark.createDataFrame(data).toDF(\"name.fname\",\"gender\")\n",
    "df.printSchema()\n",
    "df.select(df.gender).show()\n",
    "df.select(df[\"gender\"]).show()\n",
    "df.select(df[\"`name.fname`\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1184f821-094e-4c06-93ed-64d8e50528fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|    23|\n",
      "|    40|\n",
      "+------+\n",
      "\n",
      "+----------+\n",
      "|name.fname|\n",
      "+----------+\n",
      "|     James|\n",
      "|       Ann|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.63 col()함수\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"gender\")).show()\n",
    "df.select(col(\"`name.fname`\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "208d3541-37ec-4c12-aa26-ed0e3ad861bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- prop: struct (nullable = true)\n",
      " |    |-- hair: string (nullable = true)\n",
      " |    |-- eye: string (nullable = true)\n",
      "\n",
      "+-----+-------------+\n",
      "| name|         prop|\n",
      "+-----+-------------+\n",
      "|James|{black, blue}|\n",
      "|  Ann|{grey, black}|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.64 Row()함수 이용 데이터 생성\n",
    "# Row():컬럼명과 해당값, 중첩컬럼데이터구성가능\n",
    "from pyspark.sql import Row\n",
    "data=[Row(name=\"James\",prop=Row(hair=\"black\",eye=\"blue\")),\n",
    "      Row(name=\"Ann\",prop=Row(hair=\"grey\",eye=\"black\"))]\n",
    "df=spark.createDataFrame(data)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aeeffad6-7631-4b0a-b57e-801e6df30592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|prop.hair|\n",
      "+---------+\n",
      "|    black|\n",
      "|     grey|\n",
      "+---------+\n",
      "\n",
      "+-----+\n",
      "| hair|\n",
      "+-----+\n",
      "|black|\n",
      "| grey|\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "| hair|\n",
      "+-----+\n",
      "|black|\n",
      "| grey|\n",
      "+-----+\n",
      "\n",
      "+-----+-----+\n",
      "| hair|  eye|\n",
      "+-----+-----+\n",
      "|black| blue|\n",
      "| grey|black|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.65 \n",
    "# .:중첩구조 데이터에 접근, *:중첩구조의 컬럼 풀어서 반환\n",
    "df.select(df.prop.hair).show()\n",
    "df.select(df[\"prop.hair\"]).show()\n",
    "df.select(col(\"prop.hair\")).show()\n",
    "df.select(col(\"prop.*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "389f5344-9d5f-491b-9c47-88788e0ce6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "| 100|   2|   1|\n",
      "| 200|   3|   4|\n",
      "| 300|   4|   4|\n",
      "+----+----+----+\n",
      "\n",
      "+-------------+\n",
      "|(col1 + col2)|\n",
      "+-------------+\n",
      "|          102|\n",
      "|          203|\n",
      "|          304|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 - col2)|\n",
      "+-------------+\n",
      "|           98|\n",
      "|          197|\n",
      "|          296|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 * col2)|\n",
      "+-------------+\n",
      "|          200|\n",
      "|          600|\n",
      "|         1200|\n",
      "+-------------+\n",
      "\n",
      "+-----------------+\n",
      "|    (col1 / col2)|\n",
      "+-----------------+\n",
      "|             50.0|\n",
      "|66.66666666666667|\n",
      "|             75.0|\n",
      "+-----------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 % col2)|\n",
      "+-------------+\n",
      "|            0|\n",
      "|            2|\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 > col3)|\n",
      "+-------------+\n",
      "|         true|\n",
      "|        false|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 < col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|         true|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 = col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|        false|\n",
      "|         true|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.66,67 컬럼의 연산 및 비교\n",
    "# 비교 연산자(<,>,==) -> Boolean을 반환\n",
    "data=[(100,2,1),(200,3,4),(300,4,4)]\n",
    "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\",\"col3\")\n",
    "df.show()\n",
    "\n",
    "df.select(df.col1 + df.col2).show()\n",
    "df.select(df.col1 - df.col2).show() \n",
    "df.select(df.col1 * df.col2).show()\n",
    "df.select(df.col1 / df.col2).show() \n",
    "df.select(df.col1 % df.col2).show() # 나머지\n",
    "df.select(df.col2 > df.col3).show()\n",
    "df.select(df.col2 < df.col3).show()\n",
    "df.select(df.col2 == df.col3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e215e448-88c0-40cf-b19d-2ff6acc47cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     James|     Bond|\n",
      "|       Ann|    Varsa|\n",
      "|Tom Cruise|      XXX|\n",
      "| Tom Brand|     null|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.68,69\n",
    "data=[(\"James\",\"Bond\",\"100\",None),\n",
    "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
    "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
    "      (\"Tom Brand\",None,\"400\",'M')] \n",
    "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
    "df=spark.createDataFrame(data,columns)\n",
    "df.show()\n",
    "\n",
    "# alias 함수 사용하여 별칭이용\n",
    "df.select(df.fname.alias(\"first_name\"), df.lname.alias(\"last_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb8d51b4-c5f6-4f52-9f3d-5150c49a3240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|      fullName|\n",
      "+--------------+\n",
      "|    James,Bond|\n",
      "|     Ann,Varsa|\n",
      "|Tom Cruise,XXX|\n",
      "|          null|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.70 expr():컬럼 합쳐서 표현\n",
    "from pyspark.sql.functions import expr\n",
    "df.select(expr(\" fname ||','|| lname\").alias(\"fullName\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8944cb8d-1fb1-4b8c-88bb-04c80d90f6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|     James| Bond|100|  null|\n",
      "| Tom Brand| null|400|     M|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.71 asc:오름차순, desc:내림차순\n",
    "df.sort(df.fname.asc()).show()\n",
    "df.sort(df.fname.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "034a45ca-3924-4b02-a226-68a3536e7261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.72 cast: 형변환\n",
    "df.printSchema()\n",
    "df.select(df.fname,df.id.cast(\"int\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b17529f7-dbbf-4d9a-9aee-4a06b95fd9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "|James| Bond|100|  null|\n",
      "|  Ann|Varsa|200|     F|\n",
      "+-----+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "+-----+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.73 between: 범위, contains: 특정 문자열 포함행 출력\n",
    "# ==은 풀 문자열 검색 수행\n",
    "df.filter(df.id.between(100,300)).show()\n",
    "df.filter(df.fname.contains(\"Cruise\")).show()\n",
    "df.filter(df.fname == \"Cruise\").show()\n",
    "df.filter(df.fname == \"Tom Cruise\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64204559-60cf-49e0-ab0b-0b7b430a391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.74 startswith: 특정문자 시작되는 행 검색, endswith: 특정문자 끝부터 시작하는 행 검색\n",
    "df.filter(df.fname.startswith(\"T\")).show()\n",
    "df.filter(df.fname.endswith(\"Cruise\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24801449-d301-41c4-a993-a3b5b33ffa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| null|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.75 isNull: null만 출력, isNotNull: null 제외출력\n",
    "df.filter(df.lname.isNull()).show()\n",
    "df.filter(df.lname.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7381b90-00df-425b-a03c-081e194a0cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|substr|\n",
      "+------+\n",
      "|    Ja|\n",
      "|    An|\n",
      "|    To|\n",
      "|    To|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.76 substr:특정컬럼에 원하는 문자열 만큼\n",
    "# 문자열의 첫번째부터 두번째까지\n",
    "df.select(df.fname.substr(1,2).alias(\"substr\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61f18b16-7564-4f1b-b980-283df78a1ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+----------+\n",
      "|     fname|lname|new_gender|\n",
      "+----------+-----+----------+\n",
      "|     James| Bond|      null|\n",
      "|       Ann|Varsa|    Female|\n",
      "|Tom Cruise|  XXX|      null|\n",
      "| Tom Brand| null|      Male|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.77 when(): 다양한 조건들을 순서적으로 추가\n",
    "# otherwise(): 그외의 조건\n",
    "df.show()\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "df.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\")\n",
    ".when(df.gender==\"F\",\"Female\")\n",
    ".alias(\"new_gender\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ca65e44-151b-48b0-af7d-20f262e1a8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+\n",
      "|fname|lname| id|\n",
      "+-----+-----+---+\n",
      "|James| Bond|100|\n",
      "|  Ann|Varsa|200|\n",
      "+-----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.78 isin:특정 값 존재 행 출력\n",
    "li=[\"100\",\"200\"]\n",
    "df.select(df.fname,df.lname,df.id).filter(df.id.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4cf980d-9541-4245-88d1-8ccb8d3b5681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+\n",
      "|     fname|lname| id|\n",
      "+----------+-----+---+\n",
      "|     James| Bond|100|\n",
      "|       Ann|Varsa|200|\n",
      "|Tom Cruise|  XXX|400|\n",
      "+----------+-----+---+\n",
      "only showing top 3 rows\n",
      "\n",
      "+---+------+\n",
      "| id|gender|\n",
      "+---+------+\n",
      "|100|  null|\n",
      "|200|     F|\n",
      "|400|      |\n",
      "+---+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.79 Select\n",
    "# p.80 [:] : 원하는 컬럼의 길이만큼 출력(열의길이)\n",
    "df.show()\n",
    "df.select(df.columns[:3]).show(3)\n",
    "df.select(df.columns[2:4]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92ee3b1e-8a2b-4a5d-82d5-f101606f9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.81 withColumn: 컬럼 생성 or 변경, cast: 형변환\n",
    "from pyspark.sql.functions import col\n",
    "df2 = df.withColumn(\"id\",col(\"id\").cast(\"Integer\"))\n",
    "df2.printSchema()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf21c869-62c9-4efa-b8c5-79a5db00a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+------+\n",
      "|     fname|lname|     id|gender|\n",
      "+----------+-----+-------+------+\n",
      "|     James| Bond|10000.0|  null|\n",
      "|       Ann|Varsa|20000.0|     F|\n",
      "|Tom Cruise|  XXX|40000.0|      |\n",
      "| Tom Brand| null|40000.0|     M|\n",
      "+----------+-----+-------+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.82 col()에 연산 수행\n",
    "df3 = df.withColumn(\"id\",col(\"id\")*100)\n",
    "df3.show()\n",
    "df.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0658a531-e0f8-4890-8ebd-18df92787c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+------+\n",
      "|     fname|lname| id|gender|new_id|\n",
      "+----------+-----+---+------+------+\n",
      "|     James| Bond|100|  null|-100.0|\n",
      "|       Ann|Varsa|200|     F|-200.0|\n",
      "|Tom Cruise|  XXX|400|      |-400.0|\n",
      "| Tom Brand| null|400|     M|-400.0|\n",
      "+----------+-----+---+------+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.83 새로운 컬럼 생성\n",
    "df4 = df.withColumn(\"new_id\",col(\"id\")* -1)\n",
    "df4.show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3dd7ef36-de7f-4dfd-b888-687e165f938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------+------+\n",
      "|     fname|lname|new_id|gender|\n",
      "+----------+-----+------+------+\n",
      "|     James| Bond|   100|  null|\n",
      "|       Ann|Varsa|   200|     F|\n",
      "|Tom Cruise|  XXX|   400|      |\n",
      "| Tom Brand| null|   400|     M|\n",
      "+----------+-----+------+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.84 withColumnRenamed: 컬럼명 변경(기존컬럼명,변경컬럼명)\n",
    "df5 = df.withColumnRenamed(\"id\",\"new_id\")\n",
    "df5.show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47bd7377-93e9-4eae-b0e3-5534c3556985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+------+------+\n",
      "| new_fname|lname|new_id|gender|\n",
      "+----------+-----+------+------+\n",
      "|     James| Bond|   100|  null|\n",
      "|       Ann|Varsa|   200|     F|\n",
      "|Tom Cruise|  XXX|   400|      |\n",
      "| Tom Brand| null|   400|     M|\n",
      "+----------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.85 다수의 컬럼명 변경 : .을 이용하여 계속적으로 함수 사용\n",
    "df.show()\n",
    "df.withColumnRenamed(\"id\",\"new_id\").withColumnRenamed(\"fname\", \"new_fname\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5128ed41-ff31-478d-83ac-d987d48403ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+\n",
      "|   newCol1|newCol2|newCol3|newCol4|\n",
      "+----------+-------+-------+-------+\n",
      "|     James|   Bond|    100|   null|\n",
      "|       Ann|  Varsa|    200|      F|\n",
      "|Tom Cruise|    XXX|    400|       |\n",
      "| Tom Brand|   null|    400|      M|\n",
      "+----------+-------+-------+-------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.86 모든 컬럼명 변경\n",
    "# 새로운 컬럼명 리스트 생성 -> toDF의 *: 모든 값을 가져오겠다는 의미\n",
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "new_df = df.toDF(*newColumns)\n",
    "new_df.show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85971847-e867-4677-bfb7-9ab42c9d8c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+\n",
      "|     fname|lname| id|\n",
      "+----------+-----+---+\n",
      "|     James| Bond|100|\n",
      "|       Ann|Varsa|200|\n",
      "|Tom Cruise|  XXX|400|\n",
      "| Tom Brand| null|400|\n",
      "+----------+-----+---+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.87 drop: 컬럼 삭제\n",
    "df6 = df.drop(\"gender\")\n",
    "df6.show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7bcfc4d-0984-4316-af9e-65bc18a113ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "|James| Bond|100|  null|\n",
      "+-----+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 23.09.01\n",
    "# p.88 filter(): 원하는 데이터 출력\n",
    "# 일치하지 않음: !=, ~(...==...)\n",
    "df.show()\n",
    "df.filter(df.fname == \"James\").show()\n",
    "df.filter(df.fname != \"James\").show() \n",
    "df.filter(~(df.fname == \"James\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed62cfac-05db-46cf-bfe5-7bc3ab392c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| null|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.89\n",
    "df.show()\n",
    "df.filter(\"gender == 'M'\").show()\n",
    "df.filter(\"gender != 'M'\").show()\n",
    "df.filter(\"gender <> 'M'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70fbfcb1-ca71-45ce-bba6-473481faa142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+-----+-----+---+------+\n",
      "|fname|lname|id |gender|\n",
      "+-----+-----+---+------+\n",
      "|Ann  |Varsa|200|F     |\n",
      "+-----+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.90 AND/OR/NOT 연산\n",
    "df.show()\n",
    "df.filter((df.gender == \"F\") & (df.fname == \"Ann\")).show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be707a46-550d-4e5f-8f26-6ca2d5be54c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.91 like(): 원하는 문자열이 포함된 데이터 조회\n",
    "df.show()\n",
    "df.filter(df.fname.like(\"Tom%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ed47866-9e4d-4868-b466-95457ef7476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3000  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Maria        |Finance   |3000  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.92\n",
    "data = [(\"James\", \"Sales\", 3000),\n",
    "  (\"Robert\", \"Sales\", 4100),\n",
    "  (\"Maria\", \"Finance\", 3000),\n",
    "  (\"James\", \"Sales\", 3000),\n",
    "  (\"Scott\", \"Finance\", 3000),\n",
    "  (\"Jen\", \"Finance\", 3900),\n",
    "  (\"Maria\", \"Finance\", 3000),\n",
    "]\n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae42a632-f8c9-490e-9b2f-b0a40c4e37f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count: 5\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Jen          |Finance   |3900  |\n",
      "|Scott        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "+-------------+----------+------+\n",
      "\n",
      "Distinct count: 5\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Jen          |Finance   |3900  |\n",
      "|Scott        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.93 Distinct(),dropDuplicates() : 중복제거\n",
    "distinctDF = df.distinct()\n",
    "print(\"Distinct count: \"+str(distinctDF.count()))\n",
    "distinctDF.show(truncate=False)\n",
    "\n",
    "df2 = df.dropDuplicates()\n",
    "print(\"Distinct count: \"+str(df2.count()))\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36f749ab-b7e6-445c-ac77-61d0b7e12b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Maria|   Finance|  3000|\n",
      "+-------------+----------+------+\n",
      "\n",
      "Distinct count of department & salary : 4\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Maria        |Finance   |3000  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.94 dropDuplicates() : 중복을 제외하고 싶은 컬럼 다수 지정 가능\n",
    "df.show()\n",
    "dropDisDF = df.dropDuplicates([\"department\",\"salary\"])\n",
    "print(\"Distinct count of department & salary : \"+str(dropDisDF.count()))\n",
    "dropDisDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd17cd36-19b5-4908-b512-f258c0c88a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Maria|   Finance|  3000|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        James|     Sales|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        James|     Sales|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.95 Sort:컬럼의 데이터 정렬\n",
    "df.show()\n",
    "df.sort(\"department\",\"salary\").show()\n",
    "df.sort(col(\"department\"),col(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1fc92a15-5216-4e2e-b167-b97f4736aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Maria|   Finance|  3000|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        James|     Sales|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        James|     Sales|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.96 orderBy: 데이터 정렬\n",
    "df.show()\n",
    "df.orderBy(\"department\",\"salary\").show()\n",
    "df.orderBy(col(\"department\"),col(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb44fc4d-8def-433d-897a-ee797e46755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        James|     Sales|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        James|     Sales|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        James|     Sales|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.97 asc:오름차순, desc:내림차순\n",
    "df.sort(df.department.asc(),df.salary.desc()).show()\n",
    "df.sort(col(\"department\").asc(),col(\"salary\").desc()).show()\n",
    "df.orderBy(col(\"department\").asc(),col(\"salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77c65387-50c4-488f-a7ea-e87c2d591f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|department|salary|\n",
      "+----------+------+\n",
      "|   Finance|  3000|\n",
      "|   Finance|  3000|\n",
      "|   Finance|  3900|\n",
      "|   Finance|  3000|\n",
      "|     Sales|  3000|\n",
      "|     Sales|  4100|\n",
      "|     Sales|  3000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.98 sql쿼리처리->ViewFrame을 생성\n",
    "df.createOrReplaceTempView(\"ViewFrame\")\n",
    "spark.sql(\"select department, salary from ViewFrame ORDER BY department asc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17fcef54-9a70-433a-9f99-3d600053eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3000|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Maria|   Finance|  3000|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|     Sales|    3|\n",
      "|   Finance|    4|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# P.99 groupBy: 원하는 컬럼 그룹화, count:그룹화한 데이터의 개수\n",
    "df.show()\n",
    "df.groupBy(\"department\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7cfa176-4b77-46cb-ab37-59ab8875c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|department|sum(salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|      10100|\n",
      "|   Finance|      12900|\n",
      "+----------+-----------+\n",
      "\n",
      "+----------+-----------+\n",
      "|department|min(salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|       3000|\n",
      "|   Finance|       3000|\n",
      "+----------+-----------+\n",
      "\n",
      "+----------+-----------+\n",
      "|department|max(salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|       4100|\n",
      "|   Finance|       3900|\n",
      "+----------+-----------+\n",
      "\n",
      "+----------+------------------+\n",
      "|department|       avg(salary)|\n",
      "+----------+------------------+\n",
      "|     Sales|3366.6666666666665|\n",
      "|   Finance|            3225.0|\n",
      "+----------+------------------+\n",
      "\n",
      "+----------+------------------+\n",
      "|department|       avg(salary)|\n",
      "+----------+------------------+\n",
      "|     Sales|3366.6666666666665|\n",
      "|   Finance|            3225.0|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.100 groupby연산:sum,min,max,avg,mean\n",
    "df.groupBy(\"department\").sum(\"salary\").show()\n",
    "df.groupBy(\"department\").min(\"salary\").show()\n",
    "df.groupBy(\"department\").max(\"salary\").show()\n",
    "df.groupBy(\"department\").avg( \"salary\").show()\n",
    "df.groupBy(\"department\").mean( \"salary\") .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a97ea070-61ba-4e14-848b-36186d216b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----------+\n",
      "|employee_name|department|sum(salary)|\n",
      "+-------------+----------+-----------+\n",
      "|          Jen|   Finance|       3900|\n",
      "|        James|     Sales|       6000|\n",
      "|        Maria|   Finance|       6000|\n",
      "|        Scott|   Finance|       3000|\n",
      "|       Robert|     Sales|       4100|\n",
      "+-------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.101 groupBy: 다수의 컬럼 그룹화 가능\n",
    "df.groupBy(\"employee_name\",\"department\").sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d0cfda8-c2ce-4dab-8adf-0d66b4c0b05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.102 Join \n",
    "# 데이터프레임 2개 생성\n",
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000),\n",
    "(2,\"Rose\",1,\"2010\",\"20\",\"M\",4000),\n",
    "(3,\"Williams\",1,\"2010\",\"10\",\"M\",1000),\n",
    "(4,\"Jones\",2,\"2005\",\"10\",\"F\",2000),\n",
    "(5,\"Brown\",2,\"2010\",\"40\",\"\",-1),\n",
    "(6,\"Brown\",2,\"2010\",\"50\",\"\",-1)]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\",\"emp_dept_id\",\"gender\",\"salary\"]\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show(truncate=False)\n",
    "\n",
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89c739c2-c8de-4fca-821d-5569a0e0c003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.103 ~ 106\n",
    "# inner join\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\").show()\n",
    "\n",
    "#full outer join\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"fullouter\").show()\n",
    "\n",
    "#left outer join\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftouter\").show()\n",
    "\n",
    "#right outer join\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\").show()\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5aa799d9-5490-4d41-aa36-48e8eb9f0e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|     6|Brown|              2|       2010|         50|      |    -1|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.107\n",
    "#left semi join : inner join과 유사\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftsemi\").show()\n",
    "\n",
    "#left anti join: left semi join과 반대\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftanti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f34b6ad-743c-4994-b4ab-929eb6d72d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "+------+--------+---------------+-----------------+\n",
      "|emp_id|    name|superior_emp_id|superior_emp_name|\n",
      "+------+--------+---------------+-----------------+\n",
      "|     2|    Rose|              1|            Smith|\n",
      "|     3|Williams|              1|            Smith|\n",
      "|     4|   Jones|              2|             Rose|\n",
      "|     5|   Brown|              2|             Rose|\n",
      "|     6|   Brown|              2|             Rose|\n",
      "+------+--------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.108\n",
    "#self join\n",
    "empDF.show()\n",
    "empDF.alias(\"emp1\").join(empDF.alias(\"emp2\"), \n",
    "col(\"emp1.superior_emp_id\") == col(\"emp2.emp_id\"),\"inner\").select(col(\"emp1.emp_id\"),col(\"emp1.name\"),\n",
    "col(\"emp2.emp_id\").alias(\"superior_emp_id\"), col(\"emp2.name\").alias(\"superior_emp_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f8913839-454c-4c4d-87a9-5bd7f61944b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col_1: string (nullable = true)\n",
      " |-- col_2: string (nullable = true)\n",
      " |-- col_3: string (nullable = true)\n",
      "\n",
      "+-----+-----+-----+\n",
      "|col_1|col_2|col_3|\n",
      "+-----+-----+-----+\n",
      "|A    |B    |C    |\n",
      "|A    |B    |D    |\n",
      "|A    |B    |E    |\n",
      "|A    |B    |F    |\n",
      "|A    |B    |D    |\n",
      "+-----+-----+-----+\n",
      "\n",
      "root\n",
      " |-- col_1: string (nullable = true)\n",
      " |-- col_2: string (nullable = true)\n",
      " |-- col_3: string (nullable = true)\n",
      "\n",
      "+-----+-----+-----+\n",
      "|col_1|col_2|col_3|\n",
      "+-----+-----+-----+\n",
      "|A    |B    |G    |\n",
      "|A    |B    |H    |\n",
      "|A    |B    |I    |\n",
      "|A    |B    |F    |\n",
      "|A    |B    |D    |\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.109 Union\n",
    "# 데이터프레임 2개 생성\n",
    "simpleData = [(\"A\",\"B\",\"C\"), (\"A\",\"B\",\"D\"), (\"A\",\"B\",\"E\"), (\"A\",\"B\",\"F\"), (\"A\",\"B\",\"D\")]\n",
    "columns = [\"col_1\",\"col_2\",\"col_3\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "simpleData2 = [(\"A\",\"B\",\"G\"), (\"A\",\"B\",\"H\"), (\"A\",\"B\",\"I\"), (\"A\",\"B\",\"F\"), (\"A\",\"B\",\"D\")]\n",
    "columns2 = [\"col_1\",\"col_2\",\"col_3\"]\n",
    "df2 = spark.createDataFrame(data = simpleData2, schema = columns2)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3167952d-366a-4dc8-8833-67d885ece2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|col_1|col_2|col_3|\n",
      "+-----+-----+-----+\n",
      "|    A|    B|    C|\n",
      "|    A|    B|    D|\n",
      "|    A|    B|    E|\n",
      "|    A|    B|    F|\n",
      "|    A|    B|    D|\n",
      "|    A|    B|    G|\n",
      "|    A|    B|    H|\n",
      "|    A|    B|    I|\n",
      "|    A|    B|    F|\n",
      "|    A|    B|    D|\n",
      "+-----+-----+-----+\n",
      "\n",
      "+-----+-----+-----+\n",
      "|col_1|col_2|col_3|\n",
      "+-----+-----+-----+\n",
      "|    A|    B|    E|\n",
      "|    A|    B|    C|\n",
      "|    A|    B|    D|\n",
      "|    A|    B|    F|\n",
      "|    A|    B|    H|\n",
      "|    A|    B|    I|\n",
      "|    A|    B|    G|\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.110 Union: 합병\n",
    "unionDF = df.union(df2)\n",
    "unionDF.show()\n",
    "\n",
    "disDF = df.union(df2).distinct()\n",
    "disDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "afe117d0-3434-44b2-a5e2-74b717e8d0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Seqno|        Name|\n",
      "+-----+------------+\n",
      "|    1|  john jones|\n",
      "|    2|tracey smith|\n",
      "|    3| amy sanders|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.111 함수생성\n",
    "def convertCase(str):\n",
    "    resStr=\"\"\n",
    "    arr = str.split(\" \")\n",
    "    for x in arr:\n",
    "       resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n",
    "    return resStr\n",
    "\n",
    "columns = [\"Seqno\",\"Name\"]\n",
    "data = [(\"1\", \"john jones\"),(\"2\", \"tracey smith\"),(\"3\", \"amy sanders\")]\n",
    "df = spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "795efeee-ead3-4381-8493-8ad4d2578d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|Seqno|         Name|\n",
      "+-----+-------------+\n",
      "|    1|  John Jones |\n",
      "|    2|Tracey Smith |\n",
      "|    3| Amy Sanders |\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.112 작성한 함수는 바로 사용할 수 없고 Pyspark의 udf 함수를 우선 적용하여야함\n",
    "from pyspark.sql.functions import udf\n",
    "convertUDF = udf(lambda z: convertCase(z))\n",
    "df.select(col(\"Seqno\"),convertUDF(col(\"Name\")).alias(\"Name\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1f8bec0e-fa97-4878-8eaf-e13101abd2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C'], ['D', 'E', 'F'], ['G', 'H', 'I']]\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n"
     ]
    }
   ],
   "source": [
    "# p.113\n",
    "# map(): RDD 각 요소에 함수를 적용\n",
    "# flatmap(): map으로 반환된 결과의 각 요소를 반환, 한번에 처리\n",
    "rdd = sc.parallelize(['A,B,C','D,E,F','G,H,I'])\n",
    "\n",
    "map_rdd = rdd.map(lambda x: x.split(','))\n",
    "print(map_rdd.collect())\n",
    "\n",
    "flatmap_rdd = rdd.flatMap(lambda x: x.split(','))\n",
    "print(flatmap_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64579d52-8ab9-480d-86bd-6a760800c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+\n",
      "|firstname|lastname|gender|salary|\n",
      "+---------+--------+------+------+\n",
      "|    James|   Smith|     M|    30|\n",
      "|     Anna|    Rose|     F|    41|\n",
      "|   Robert|Williams|     M|    62|\n",
      "+---------+--------+------+------+\n",
      "\n",
      "[('James,Smith', 'M', 60), ('Anna,Rose', 'F', 82), ('Robert,Williams', 'M', 124)]\n",
      "['James,Smith', 'M', 60, 'Anna,Rose', 'F', 82, 'Robert,Williams', 'M', 124]\n"
     ]
    }
   ],
   "source": [
    "# p.114\n",
    "# map:하나의 행이 하나의 튜플로 구성\n",
    "# flatmap: 모든행이 한번에 처리\n",
    "data = [('James','Smith','M',30),('Anna','Rose','F',41),('Robert','Williams','M',62)]\n",
    "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.show()\n",
    "\n",
    "rdd2=df.rdd.map(lambda x: (x[0] + \",\" + x[1], x[2], x[3]*2))\n",
    "print(rdd2.collect())\n",
    "\n",
    "rdd3=df.rdd.flatMap(lambda x: (x[0] + \",\" + x[1], x[2], x[3]*2))  \n",
    "print(rdd3.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da4379e0-32a4-482f-9195-c643cced12cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  4|\n",
      "| 14|\n",
      "| 18|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.115 sample: 무작위 추출 / 0~1 = 0~100%\n",
    "df=spark.range(20)\n",
    "sample_df = df.sample(0.2)\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7006975a-3842-4176-9d18-18dffb33464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  4|\n",
      "| 19|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.range(20)\n",
    "sample_df = df.sample(0.2)\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ef56d79-4a05-4580-bd39-6183bc22fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  4|\n",
      "| 19|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  4|\n",
      "| 19|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "| 10|\n",
      "| 19|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "| 10|\n",
      "| 19|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.116 시드값 추가하여 샘플링 데이터 기록\n",
    "df.sample(0.2,123).show()\n",
    "df.sample(0.2,123).show()\n",
    "df.sample(0.2,456).show()\n",
    "df.sample(0.2,456).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c3b8d28-0752-4e6c-9b3e-8d7d39fa0dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "| 10|\n",
      "| 14|\n",
      "| 14|\n",
      "| 15|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "| 13|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.117 True 입력시 중복 허용하여 샘플링\n",
    "df.sample(True,0.2).show()\n",
    "df.sample(0.2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bb9a29ce-756e-44ec-91b9-76e94ba0abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- population: integer (nullable = true)\n",
      "\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|id |zipcode|type    |city               |state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|1  |704    |STANDARD|null               |PR   |30100     |\n",
      "|2  |704    |null    |PASEO COSTA DEL SUR|PR   |null      |\n",
      "|3  |709    |null    |BDA SAN LUIS       |PR   |3700      |\n",
      "|4  |76166  |UNIQUE  |CINGULAR WIRELESS  |TX   |84000     |\n",
      "|5  |76177  |STANDARD|null               |TX   |null      |\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.118 fill(): Dataframe 데이터가 0 등일때 전처리를 할 수 있는 기능\n",
    "# csv파일 로드\n",
    "df = spark.read.options(header='true', inferSchema='true').csv(\"small_zipcode.csv\")\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9727103-8b10-46b0-bc49-1efa272123ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-----+----------+\n",
      "| id|zipcode|    type|               city|state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|  1|    704|STANDARD|               null|   PR|     30100|\n",
      "|  2|    704|    null|PASEO COSTA DEL SUR|   PR|         0|\n",
      "|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n",
      "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
      "|  5|  76177|STANDARD|               null|   TX|         0|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "| id|zipcode|    type|               city|state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|  1|    704|STANDARD|               null|   PR|     30100|\n",
      "|  2|    704|    null|PASEO COSTA DEL SUR|   PR|         0|\n",
      "|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n",
      "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
      "|  5|  76177|STANDARD|               null|   TX|         0|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.119 fill함수 내에 값들을 0으로 지정하면 기존의 null값을 0으로 변경\n",
    "# subset: 지정컬럼의 데이터만 변경\n",
    "df.na.fill(value=0).show()\n",
    "df.na.fill(value=0,subset=[\"population\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f9433859-0513-46e2-874c-f2d1500752a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-----+----------+\n",
      "| id|zipcode|    type|               city|state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|  1|    704|STANDARD|            unknown|   PR|     30100|\n",
      "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n",
      "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
      "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
      "|  5|  76177|STANDARD|            unknown|   TX|      null|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "| id|zipcode|    type|               city|state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|  1|    704|STANDARD|            unknown|   PR|     30100|\n",
      "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      null|\n",
      "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
      "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
      "|  5|  76177|STANDARD|            unknown|   TX|      null|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.120 fill: 특정 문자열로 변경(빈문자열\"\"로도 가능)\n",
    "df.na.fill(\"unknown\",[\"city\"]).na.fill(\"\",[\"type\"]).show()\n",
    "# json 타입의 문서형을 입력값으로 설정\n",
    "df.na.fill({\"city\": \"unknown\", \"type\": \"\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54fc1f96-4f79-42d2-ad18-60ad6b38cffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Amount: long (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------+------+-------+\n",
      "|Product|Amount|Country|\n",
      "+-------+------+-------+\n",
      "|Banana |1000  |USA    |\n",
      "|Carrots|1500  |USA    |\n",
      "|Beans  |1600  |USA    |\n",
      "|Banana |2000  |Canada |\n",
      "|Carrots|2000  |Canada |\n",
      "|Beans  |2000  |Mexico |\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.121\n",
    "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"),\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e08a9673-0b68-46d7-b996-8b8f0284ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Canada: long (nullable = true)\n",
      " |-- Mexico: long (nullable = true)\n",
      " |-- USA: long (nullable = true)\n",
      "\n",
      "+-------+------+------+----+\n",
      "|Product|Canada|Mexico|USA |\n",
      "+-------+------+------+----+\n",
      "|Beans  |null  |2000  |1600|\n",
      "|Banana |2000  |null  |1000|\n",
      "|Carrots|2000  |null  |1500|\n",
      "+-------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.122 Pivot: groupBy 그룹화를 지정하고 pivot 함수 사용\n",
    "pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b807c1f3-08bb-41d0-a1f9-e1fcab1f41a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languagesAtWork: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      " |-- previousState: string (nullable = true)\n",
      "\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|        name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.123 ArrayType: 배열 형태 데이터가 입력되고자 하는 컬럼에 적용\n",
    "data = [(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],\"OH\",\"CA\")]\n",
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "schema = StructType([ \n",
    "    StructField(\"name\",StringType(),True), \n",
    "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True), \n",
    "    StructField(\"languagesAtWork\",ArrayType(StringType()),True), \n",
    "    StructField(\"currentState\", StringType(), True), \n",
    "    StructField(\"previousState\", StringType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f41132ca-6868-4d1f-b348-d84ebd25dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        name|  col|\n",
      "+------------+-----+\n",
      "|James,,Smith| Java|\n",
      "|James,,Smith|Scala|\n",
      "|James,,Smith|  C++|\n",
      "+------------+-----+\n",
      "\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|        name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.124 explode: 배열로 이루어진 컬럼에 적용하여 배열의 데이터를 풀어서 출력\n",
    "from pyspark.sql.functions import explode\n",
    "df.select(df.name,explode(df.languagesAtSchool)).show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "791b9727-af84-4720-870d-f3b9e9ec3594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|     nameAsArray|\n",
      "+----------------+\n",
      "|[James, , Smith]|\n",
      "+----------------+\n",
      "\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|        name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.125 split:특정기호로 이루어진 데이터를 배열 형태로 구성\n",
    "from pyspark.sql.functions import split\n",
    "df.select(split(df.name,\",\").alias(\"nameAsArray\")).show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "150590cd-24de-4a64-98ba-5df68f2abeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|        name|  States|\n",
      "+------------+--------+\n",
      "|James,,Smith|[OH, CA]|\n",
      "+------------+--------+\n",
      "\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|        name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.126 array: 다수의 열에 있는 데이터 병합하여 새로운 배열 형태의 컬럼 생성\n",
    "from pyspark.sql.functions import array\n",
    "df.select(df.name,array(df.currentState,df.previousState).alias(\"States\")).show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6281527-5c88-4c3c-9cd8-b70cd7cadd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|        name|array_contains|\n",
      "+------------+--------------+\n",
      "|James,,Smith|          true|\n",
      "+------------+--------------+\n",
      "\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|        name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "|James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
      "+------------+------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# p.127 array_contains: 특정 컬럼의 값이 있다면, 해당 컬럼의 데이터를 Boolean(True,False)로 표현 가능\n",
    "from pyspark.sql.functions import array_contains\n",
    "df.select(df.name,array_contains(df.languagesAtSchool,\"Java\").alias(\"array_contains\")).show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de4ccf-d85a-4a5d-8533-25999c80e43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
